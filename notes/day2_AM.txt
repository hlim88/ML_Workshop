>>> # MLW 2022-05-10 Day 2 AM
>>> # One really nice feature of sklearn, is that it comes with built in datasets
>>> from sklearn import datasets
>>> # 3 types of datasets
>>> # (1) Dataset loaders - small standard datasets (often called toy datasets)... iris is an example of this
>>> # (2) Dataset fetchers - large datasets that mimic real world datasets
>>> # These are called fetchers bescause we "fetch" a piece or all of these "larger/messier" datasets
>>> # (3) Dataset generartos - used to generate or create mock/fake datasets (really cool)
>>> # When we load these datasets, it will return something called a "bunch"
>>> # think of this as a dictionary where we can refernce things via the "dot" sytnax
>>> from sklearn import datasets
>>> dir(datasets)
['__all__',
 '__builtins__',
 '__cached__',
 '__doc__',
 '__file__',
 '__loader__',
 '__name__',
 '__package__',
 '__path__',
 '__spec__',
 '_base',
 '_california_housing',
 '_covtype',
 '_kddcup99',
 '_lfw',
 '_olivetti_faces',
 '_openml',
 '_rcv1',
 '_samples_generator',
 '_species_distributions',
 '_svmlight_format_fast',
 '_svmlight_format_io',
 '_twenty_newsgroups',
 'clear_data_home',
 'dump_svmlight_file',
 'fetch_20newsgroups',
 'fetch_20newsgroups_vectorized',
 'fetch_california_housing',
 'fetch_covtype',
 'fetch_kddcup99',
 'fetch_lfw_pairs',
 'fetch_lfw_people',
 'fetch_olivetti_faces',
 'fetch_openml',
 'fetch_rcv1',
 'fetch_species_distributions',
 'get_data_home',
 'load_boston',
 'load_breast_cancer',
 'load_diabetes',
 'load_digits',
 'load_files',
 'load_iris',
 'load_linnerud',
 'load_sample_image',
 'load_sample_images',
 'load_svmlight_file',
 'load_svmlight_files',
 'load_wine',
 'make_biclusters',
 'make_blobs',
 'make_checkerboard',
 'make_circles',
 'make_classification',
 'make_friedman1',
 'make_friedman2',
 'make_friedman3',
 'make_gaussian_quantiles',
 'make_hastie_10_2',
 'make_low_rank_matrix',
 'make_moons',
 'make_multilabel_classification',
 'make_regression',
 'make_s_curve',
 'make_sparse_coded_signal',
 'make_sparse_spd_matrix',
 'make_sparse_uncorrelated',
 'make_spd_matrix',
 'make_swiss_roll']
>>> iris = datasets.load_iris()
>>> type(iris)
sklearn.utils.Bunch
>>> dir(iris)
['DESCR', 'data', 'feature_names', 'filename', 'target', 'target_names']
>>> print(iris.DESCR)
>>> # DESCR is a data description (like data docs)
>>> dir(iris)
['DESCR', 'data', 'feature_names', 'filename', 'target', 'target_names']
>>> iris.data
array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1.4, 0.2],
       [4.7, 3.2, 1.3, 0.2],
       [4.6, 3.1, 1.5, 0.2],
       [5. , 3.6, 1.4, 0.2],
       [5.4, 3.9, 1.7, 0.4],
       [4.6, 3.4, 1.4, 0.3],
       [5. , 3.4, 1.5, 0.2],
       [4.4, 2.9, 1.4, 0.2],
       [4.9, 3.1, 1.5, 0.1],
       [5.4, 3.7, 1.5, 0.2],
       [4.8, 3.4, 1.6, 0.2],
       [4.8, 3. , 1.4, 0.1],
       [4.3, 3. , 1.1, 0.1],
       [5.8, 4. , 1.2, 0.2],
       [5.7, 4.4, 1.5, 0.4],
       [5.4, 3.9, 1.3, 0.4],
       [5.1, 3.5, 1.4, 0.3],
       [5.7, 3.8, 1.7, 0.3],
       [5.1, 3.8, 1.5, 0.3],
       [5.4, 3.4, 1.7, 0.2],
       [5.1, 3.7, 1.5, 0.4],
       [4.6, 3.6, 1. , 0.2],
       [5.1, 3.3, 1.7, 0.5],
       [4.8, 3.4, 1.9, 0.2],
       [5. , 3. , 1.6, 0.2],
       [5. , 3.4, 1.6, 0.4],
       [5.2, 3.5, 1.5, 0.2],
       [5.2, 3.4, 1.4, 0.2],
       [4.7, 3.2, 1.6, 0.2],
       [4.8, 3.1, 1.6, 0.2],
       [5.4, 3.4, 1.5, 0.4],
       [5.2, 4.1, 1.5, 0.1],
       [5.5, 4.2, 1.4, 0.2],
       [4.9, 3.1, 1.5, 0.2],
       [5. , 3.2, 1.2, 0.2],
       [5.5, 3.5, 1.3, 0.2],
       [4.9, 3.6, 1.4, 0.1],
       [4.4, 3. , 1.3, 0.2],
       [5.1, 3.4, 1.5, 0.2],
       [5. , 3.5, 1.3, 0.3],
       [4.5, 2.3, 1.3, 0.3],
       [4.4, 3.2, 1.3, 0.2],
       [5. , 3.5, 1.6, 0.6],
       [5.1, 3.8, 1.9, 0.4],
       [4.8, 3. , 1.4, 0.3],
       [5.1, 3.8, 1.6, 0.2],
       [4.6, 3.2, 1.4, 0.2],
       [5.3, 3.7, 1.5, 0.2],
       [5. , 3.3, 1.4, 0.2],
       [7. , 3.2, 4.7, 1.4],
       [6.4, 3.2, 4.5, 1.5],
       [6.9, 3.1, 4.9, 1.5],
       [5.5, 2.3, 4. , 1.3],
       [6.5, 2.8, 4.6, 1.5],
       [5.7, 2.8, 4.5, 1.3],
       [6.3, 3.3, 4.7, 1.6],
       [4.9, 2.4, 3.3, 1. ],
       [6.6, 2.9, 4.6, 1.3],
       [5.2, 2.7, 3.9, 1.4],
       [5. , 2. , 3.5, 1. ],
       [5.9, 3. , 4.2, 1.5],
       [6. , 2.2, 4. , 1. ],
       [6.1, 2.9, 4.7, 1.4],
       [5.6, 2.9, 3.6, 1.3],
       [6.7, 3.1, 4.4, 1.4],
       [5.6, 3. , 4.5, 1.5],
       [5.8, 2.7, 4.1, 1. ],
       [6.2, 2.2, 4.5, 1.5],
       [5.6, 2.5, 3.9, 1.1],
       [5.9, 3.2, 4.8, 1.8],
       [6.1, 2.8, 4. , 1.3],
       [6.3, 2.5, 4.9, 1.5],
       [6.1, 2.8, 4.7, 1.2],
       [6.4, 2.9, 4.3, 1.3],
       [6.6, 3. , 4.4, 1.4],
       [6.8, 2.8, 4.8, 1.4],
       [6.7, 3. , 5. , 1.7],
       [6. , 2.9, 4.5, 1.5],
       [5.7, 2.6, 3.5, 1. ],
       [5.5, 2.4, 3.8, 1.1],
       [5.5, 2.4, 3.7, 1. ],
       [5.8, 2.7, 3.9, 1.2],
       [6. , 2.7, 5.1, 1.6],
       [5.4, 3. , 4.5, 1.5],
       [6. , 3.4, 4.5, 1.6],
       [6.7, 3.1, 4.7, 1.5],
       [6.3, 2.3, 4.4, 1.3],
       [5.6, 3. , 4.1, 1.3],
       [5.5, 2.5, 4. , 1.3],
       [5.5, 2.6, 4.4, 1.2],
       [6.1, 3. , 4.6, 1.4],
       [5.8, 2.6, 4. , 1.2],
       [5. , 2.3, 3.3, 1. ],
       [5.6, 2.7, 4.2, 1.3],
       [5.7, 3. , 4.2, 1.2],
       [5.7, 2.9, 4.2, 1.3],
       [6.2, 2.9, 4.3, 1.3],
       [5.1, 2.5, 3. , 1.1],
       [5.7, 2.8, 4.1, 1.3],
       [6.3, 3.3, 6. , 2.5],
       [5.8, 2.7, 5.1, 1.9],
       [7.1, 3. , 5.9, 2.1],
       [6.3, 2.9, 5.6, 1.8],
       [6.5, 3. , 5.8, 2.2],
       [7.6, 3. , 6.6, 2.1],
       [4.9, 2.5, 4.5, 1.7],
       [7.3, 2.9, 6.3, 1.8],
       [6.7, 2.5, 5.8, 1.8],
       [7.2, 3.6, 6.1, 2.5],
       [6.5, 3.2, 5.1, 2. ],
       [6.4, 2.7, 5.3, 1.9],
       [6.8, 3. , 5.5, 2.1],
       [5.7, 2.5, 5. , 2. ],
       [5.8, 2.8, 5.1, 2.4],
       [6.4, 3.2, 5.3, 2.3],
       [6.5, 3. , 5.5, 1.8],
       [7.7, 3.8, 6.7, 2.2],
       [7.7, 2.6, 6.9, 2.3],
       [6. , 2.2, 5. , 1.5],
       [6.9, 3.2, 5.7, 2.3],
       [5.6, 2.8, 4.9, 2. ],
       [7.7, 2.8, 6.7, 2. ],
       [6.3, 2.7, 4.9, 1.8],
       [6.7, 3.3, 5.7, 2.1],
       [7.2, 3.2, 6. , 1.8],
       [6.2, 2.8, 4.8, 1.8],
       [6.1, 3. , 4.9, 1.8],
       [6.4, 2.8, 5.6, 2.1],
       [7.2, 3. , 5.8, 1.6],
       [7.4, 2.8, 6.1, 1.9],
       [7.9, 3.8, 6.4, 2. ],
       [6.4, 2.8, 5.6, 2.2],
       [6.3, 2.8, 5.1, 1.5],
       [6.1, 2.6, 5.6, 1.4],
       [7.7, 3. , 6.1, 2.3],
       [6.3, 3.4, 5.6, 2.4],
       [6.4, 3.1, 5.5, 1.8],
       [6. , 3. , 4.8, 1.8],
       [6.9, 3.1, 5.4, 2.1],
       [6.7, 3.1, 5.6, 2.4],
       [6.9, 3.1, 5.1, 2.3],
       [5.8, 2.7, 5.1, 1.9],
       [6.8, 3.2, 5.9, 2.3],
       [6.7, 3.3, 5.7, 2.5],
       [6.7, 3. , 5.2, 2.3],
       [6.3, 2.5, 5. , 1.9],
       [6.5, 3. , 5.2, 2. ],
       [6.2, 3.4, 5.4, 2.3],
       [5.9, 3. , 5.1, 1.8]])
>>> type(iris.data)
numpy.ndarray
>>> iris.data.shape
(150, 4)
>>> # (150, 4) means we have 150 samples and 4 features
>>> iris.feature_names
['sepal length (cm)',
 'sepal width (cm)',
 'petal length (cm)',
 'petal width (cm)']
>>> iris.target
array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
>>> # Target is a numerical representation of the classes
>>> iris.target_names
array(['setosa', 'versicolor', 'virginica'], dtype='<U10')
>>> iris.filename
'/Users/lthomas/.edm/envs/python-class/lib/python3.6/site-packages/sklearn/datasets/data/iris.csv'
>>> clear
>>> # Slide 100 Example
>>> from sklearn.svm import LinearSVC
>>> # dont worry too much about the model choice here, we will discuss in depth later on
>>> # just worry about the "workflow"
>>> iris = datasets.load_iris()
>>> model = LinearSVC(max_iter=5_000)
>>> model.fit(iris.data, iris.target)
LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=5000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0)
>>> # a few things to remember
>>> iris.data.shapw
>>> iris.data.shape
(150, 4)
>>> iris.targer
>>> iris.target
array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
>>> iris.target.shape
(150,)
>>> iris.data.shape
(150, 4)
>>> # when we do a fit, sklearn will store the things learned in our model with the "_" suffix
>>> model.classes_
array([0, 1, 2])
>>> model.intercept_
array([ 0.10956084,  1.68737546, -1.71077621])
>>> model.coef_
array([[ 0.18423193,  0.45123061, -0.80794576, -0.45071426],
       [ 0.05524655, -0.9008963 ,  0.40923438, -0.96062845],
       [-0.85059354, -0.98655992,  1.38103702,  1.86512532]])
>>> # we have 3 intercepts because we have 3 classes
>>> # we have a coef matrix that is 3x4 because we have 3 classes x 4 features and LinearSVC performs OvR (one vs rest) classification
>>> model.n_iters_
>>> model.n_iter_
2885
>>> model.score(iris.data, iris.target)
0.9666666666666667
>>> # The .score() defaults to R2 for regression problems and accuracy for classifcation
>>> # in this case, we are running a classification problem so the score is # correct / total number of samples
>>> preds = model.predict(iris.data)
>>> errors = preds != iris.target
>>> errors.sum()
5
>>> 5/len(iris.data)
0.03333333333333333
>>> 1 - 5/len(iris.data)
0.9666666666666667
>>> (len(iris.data) - errors.sum())/len(iris.data)
0.9666666666666667
>>> model.score(iris.data, iris.target)
0.9666666666666667
>>> score = model.score(iris.data, iris.targer)
>>> score = model.score(iris.data, iris.target)
>>> print(f"Accuracy: {score}")
>>> print(f"Accuracy: {score:.3f}")
>>> %matplotlib qt
>>> import matplotlib.pyplot as plt
>>> plt.figure(figsize=(10,8))
<Figure size 2000x1600 with 0 Axes>
>>> plt.scatter(iris.data[:, 0], iris.data[:, 1], c=iris.target, edgecolor='k', label='raw data')
<matplotlib.collections.PathCollection at 0x7f96123e9b38>
>>> plt.scatter(iris.data[errors, 0], iris.data[errors, 1], c='red', marker='X', s=30, label='error')
<matplotlib.collections.PathCollection at 0x7f961248fe10>
>>> plt.xlabel(iris.features_names[0])
>>> plt.xlabel(iris.feature_names[0])
Text(0.5, 117.4444444444444, 'sepal length (cm)')
>>> plt.ylabel(iris.feature_names[1])
Text(175.31944444444443, 0.5, 'sepal width (cm)')
>>> est_class = model.__class__.__name__
>>> est_class
'LinearSVC'
>>> score
0.9666666666666667
>>> plt.title(
...     'Example\n'
...     + f"Est: {est_class} \n"
...     + f"Accuracy: {score:.3f}"
...     + f"Errors: {errors.sum()}"
... )
...
Text(0.5, 1.0, 'Example\nEst: LinearSVC \nAccuracy: 0.967Errors: 5')
>>> clear
>>> # Slide 101
>>> from sklearn import datasets
>>> from sklearn.linear_model import LogisticRegression
>>> # Remember, the iris dataset is a CLASSIFICATION problem
>>> # Most models in sklearn for classification will have a "C" or say "Classifier" or "Classifcation" in the model name
>>> # The excpetion is LogisticRegresssion, even though this has regression in the model name it is actually a classifier
>>> iris = datasets.load_iris()
>>> model = LogisticRegression()
>>> print(model)
>>> model.fit(iris.data, iris.target)
LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
>>> model.score(iris.data, iris.target)  # default for classification is accuracy
0.9733333333333334
>>> model2 = LogisticRegression(max_iter=5_000)
>>> model2.fit(iris.data, iris.target)
LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=5000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
>>> model2.score(iris.data, iris.targer)
>>> model2.score(iris.data, iris.target)
0.9733333333333334
>>> preds = model.predict(iris.data, iris.target)
>>> preds = model.predict(iris.data)
>>> preds.shape
(150,)
>>> errors = preds != iris.target
>>> errors
array([False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False,  True, False,
       False, False, False, False, False,  True, False, False, False,
       False, False,  True, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False,  True, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False])
>>> errors.sum()
4
>>> 4/150
0.02666666666666667
>>> 1 - 4/150
0.9733333333333334
>>> model.score(iris.data, iris.target)  # default for classification is accuracy
0.9733333333333334
>>> # Purely for example... lets look at what is happending under the hood when we call .predict()
>>> # Using a linear regression because it is easier to interpret rather than OvR (one vs rest)
>>> from sklearn.linear_model import LinearRegression
>>> regressor = LinearRegression()
>>> # WARNING: do not do this in practice... LinearRegression is for regression problems, and iris is a classification problem
>>> regressor.fit(iris.dat, iris.target)
>>> regressor.fit(iris.data, iris.target)
LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)
>>> regressos.intercept_
>>> regressor.intercept_
0.18649524720624944
>>> regressor.coef_
array([-0.11190585, -0.04007949,  0.22864503,  0.60925205])
>>> # This is like what we say yesterday... multiplle linear regression
>>> # y_hat = B_0 + B_1 * x_1 + B_2 * x_2 + B_3 * x_3 + B_4 * x_4
>>> # B's are weights or coefficients (B_0 is the bias or intercept)
>>> # x's are features
>>> iris.data[0]
array([5.1, 3.5, 1.4, 0.2])
>>> x1, x2, x3, x4 = iris.data[0]
>>> x1
5.1
>>> x2
3.5
>>> x3
1.4
>>> x4
0.2
>>> regressor.coef_
array([-0.11190585, -0.04007949,  0.22864503,  0.60925205])
>>> b_1, b_2, b_3, b_4 = regressor.coef_
>>> b_0 = regressor.intercept_
>>> y_hat = b_0 + b_1*x_1 + b_2*x_2 + b_3*x_3 + b_4*x_4
>>> y_hat = b_0 + b_1*x1 + b_2*x2 + b_3*x3 + b_4*x4
>>> y_hat
-0.08254936159009345
>>> preds = regressor.predict(iris.data)
>>> preds
array([-8.25493616e-02, -4.01284476e-02, -4.86276768e-02,  1.22998627e-02,
       -7.53667248e-02,  5.82910066e-02,  3.83367194e-02, -4.44863248e-02,
        1.98324281e-02, -8.21970989e-02, -1.01272512e-01,  7.59348686e-04,
       -8.98630676e-02, -1.02503649e-01, -2.26652208e-01, -4.10494982e-02,
       -3.31670043e-02, -2.16241562e-02, -3.21980063e-02, -1.07834994e-02,
       -4.35196609e-02,  5.41496547e-02, -1.22062394e-01,  1.76835660e-01,
        6.93528569e-02, -5.59002750e-03,  1.00228589e-01, -7.08754443e-02,
       -8.97319983e-02,  1.99658314e-02,  1.27831946e-02,  3.26017444e-02,
       -1.55848342e-01, -1.55367344e-01, -2.12718935e-02, -1.05063936e-01,
       -1.50176206e-01, -1.25101345e-01, -7.04002332e-03, -5.56769102e-02,
       -3.32980735e-02,  7.07502372e-02, -1.50559206e-02,  2.18071051e-01,
        1.41599717e-01,  3.19873432e-02, -4.88442021e-02, -1.45725887e-02,
       -9.00819270e-02, -6.33428789e-02,  1.20248442e+00,  1.28482413e+00,
        1.32433716e+00,  1.18543801e+00,  1.31252984e+00,  1.25733961e+00,
        1.39866098e+00,  9.05746439e-01,  1.17548090e+00,  1.24103868e+00,
        9.56316654e-01,  1.28019945e+00,  9.50717416e-01,  1.31522353e+00,
        1.05874172e+00,  1.17147061e+00,  1.38236471e+00,  9.75923347e-01,
        1.34728479e+00,  1.02151661e+00,  1.59214618e+00,  1.09825476e+00,
        1.41552837e+00,  1.19738107e+00,  1.12926856e+00,  1.18666915e+00,
        1.26376188e+00,  1.49544119e+00,  1.34161032e+00,  8.53934864e-01,
        1.01385065e+00,  9.30060938e-01,  1.05204475e+00,  1.54773844e+00,
        1.40474588e+00,  1.38249578e+00,  1.30098933e+00,  1.18737134e+00,
        1.16905629e+00,  1.17742211e+00,  1.20394697e+00,  1.28835108e+00,
        1.07891720e+00,  8.98563803e-01,  1.20394464e+00,  1.11980500e+00,
        1.18473815e+00,  1.15164973e+00,  8.71689017e-01,  1.16588160e+00,
        2.24422636e+00,  1.75289522e+00,  1.90016020e+00,  1.74232371e+00,
        2.00536441e+00,  2.00425879e+00,  1.60258896e+00,  1.79046937e+00,
        1.75932217e+00,  2.15435175e+00,  1.71544659e+00,  1.73148072e+00,
        1.84227394e+00,  1.81016241e+00,  2.05351330e+00,  1.95514179e+00,
        1.69307008e+00,  2.04479432e+00,  2.19954392e+00,  1.48398847e+00,
        1.99064688e+00,  1.78646464e+00,  1.96302340e+00,  1.59028808e+00,
        1.88716969e+00,  1.72104260e+00,  1.57460622e+00,  1.60064541e+00,
        1.91791669e+00,  1.56147908e+00,  1.79848293e+00,  1.83196924e+00,
        1.97884189e+00,  1.44923353e+00,  1.53302790e+00,  2.00059610e+00,
        2.08783520e+00,  1.70025272e+00,  1.58897149e+00,  1.80421091e+00,
        2.05509670e+00,  1.85746781e+00,  1.75289522e+00,  2.04756647e+00,
        2.13087051e+00,  1.90672143e+00,  1.68209369e+00,  1.74632699e+00,
        1.99237157e+00,  1.66875559e+00])
>>> preds[0]
-0.08254936159009335
>>> y_hat
-0.08254936159009345
>>> # y_hat = B_0 + B_1 * x_1 + B_2 * x_2 + B_3 * x_3 + B_4 * x_4
>>> regressor.intercept_
0.18649524720624944
>>> regressor.coef_
array([-0.11190585, -0.04007949,  0.22864503,  0.60925205])
>>> regressor.coef_ * iris.data
array([[-0.57071986, -0.1402782 ,  0.32010304,  0.12185041],
       [-0.54833868, -0.12023846,  0.32010304,  0.12185041],
       [-0.52595751, -0.12825436,  0.29723854,  0.12185041],
       [-0.51476693, -0.12424641,  0.34296754,  0.12185041],
       [-0.55952927, -0.14428615,  0.32010304,  0.12185041],
       [-0.60429161, -0.15631   ,  0.38869655,  0.24370082],
       [-0.51476693, -0.13627025,  0.32010304,  0.18277562],
       [-0.55952927, -0.13627025,  0.34296754,  0.12185041],
       [-0.49238576, -0.11623051,  0.32010304,  0.12185041],
       [-0.54833868, -0.12424641,  0.34296754,  0.06092521],
       [-0.60429161, -0.1482941 ,  0.34296754,  0.12185041],
       [-0.5371481 , -0.13627025,  0.36583204,  0.12185041],
       [-0.5371481 , -0.12023846,  0.32010304,  0.06092521],
       [-0.48119517, -0.12023846,  0.25150953,  0.06092521],
       [-0.64905395, -0.16031795,  0.27437403,  0.12185041],
       [-0.63786337, -0.17634974,  0.34296754,  0.24370082],
       [-0.60429161, -0.15631   ,  0.29723854,  0.24370082],
       [-0.57071986, -0.1402782 ,  0.32010304,  0.18277562],
       [-0.63786337, -0.15230205,  0.38869655,  0.18277562],
       [-0.57071986, -0.15230205,  0.34296754,  0.18277562],
       [-0.60429161, -0.13627025,  0.38869655,  0.12185041],
       [-0.57071986, -0.1482941 ,  0.34296754,  0.24370082],
       [-0.51476693, -0.14428615,  0.22864503,  0.12185041],
       [-0.57071986, -0.13226231,  0.38869655,  0.30462603],
       [-0.5371481 , -0.13627025,  0.43442555,  0.12185041],
       [-0.55952927, -0.12023846,  0.36583204,  0.12185041],
       [-0.55952927, -0.13627025,  0.36583204,  0.24370082],
       [-0.58191044, -0.1402782 ,  0.34296754,  0.12185041],
       [-0.58191044, -0.13627025,  0.32010304,  0.12185041],
       [-0.52595751, -0.12825436,  0.36583204,  0.12185041],
       [-0.5371481 , -0.12424641,  0.36583204,  0.12185041],
       [-0.60429161, -0.13627025,  0.34296754,  0.24370082],
       [-0.58191044, -0.16432589,  0.34296754,  0.06092521],
       [-0.6154822 , -0.16833384,  0.32010304,  0.12185041],
       [-0.54833868, -0.12424641,  0.34296754,  0.12185041],
       [-0.55952927, -0.12825436,  0.27437403,  0.12185041],
       [-0.6154822 , -0.1402782 ,  0.29723854,  0.12185041],
       [-0.54833868, -0.14428615,  0.32010304,  0.06092521],
       [-0.49238576, -0.12023846,  0.29723854,  0.12185041],
       [-0.57071986, -0.13627025,  0.34296754,  0.12185041],
       [-0.55952927, -0.1402782 ,  0.29723854,  0.18277562],
       [-0.50357634, -0.09218282,  0.29723854,  0.18277562],
       [-0.49238576, -0.12825436,  0.29723854,  0.12185041],
       [-0.55952927, -0.1402782 ,  0.36583204,  0.36555123],
       [-0.57071986, -0.15230205,  0.43442555,  0.24370082],
       [-0.5371481 , -0.12023846,  0.32010304,  0.18277562],
       [-0.57071986, -0.15230205,  0.36583204,  0.12185041],
       [-0.51476693, -0.12825436,  0.32010304,  0.12185041],
       [-0.59310103, -0.1482941 ,  0.34296754,  0.12185041],
       [-0.55952927, -0.13226231,  0.32010304,  0.12185041],
       [-0.78334098, -0.12825436,  1.07463163,  0.85295288],
       [-0.71619747, -0.12825436,  1.02890262,  0.91387808],
       [-0.77215039, -0.12424641,  1.12036063,  0.91387808],
       [-0.6154822 , -0.09218282,  0.91458011,  0.79202767],
       [-0.72738805, -0.11222256,  1.05176713,  0.91387808],
       [-0.63786337, -0.11222256,  1.02890262,  0.79202767],
       [-0.70500688, -0.13226231,  1.07463163,  0.97480329],
       [-0.54833868, -0.09619077,  0.75452859,  0.60925205],
       [-0.73857864, -0.11623051,  1.05176713,  0.79202767],
       [-0.58191044, -0.10821461,  0.89171561,  0.85295288],
       [-0.55952927, -0.08015897,  0.8002576 ,  0.60925205],
       [-0.66024454, -0.12023846,  0.96030911,  0.91387808],
       [-0.67143512, -0.08817487,  0.91458011,  0.60925205],
       [-0.68262571, -0.11623051,  1.07463163,  0.85295288],
       [-0.62667278, -0.11623051,  0.8231221 ,  0.79202767],
       [-0.74976922, -0.12424641,  1.00603812,  0.85295288],
       [-0.62667278, -0.12023846,  1.02890262,  0.91387808],
       [-0.64905395, -0.10821461,  0.93744461,  0.60925205],
       [-0.69381629, -0.08817487,  1.02890262,  0.91387808],
       [-0.62667278, -0.10019872,  0.89171561,  0.67017726],
       [-0.66024454, -0.12825436,  1.09749613,  1.0966537 ],
       [-0.68262571, -0.11222256,  0.91458011,  0.79202767],
       [-0.70500688, -0.10019872,  1.12036063,  0.91387808],
       [-0.68262571, -0.11222256,  1.07463163,  0.73110246],
       [-0.71619747, -0.11623051,  0.98317362,  0.79202767],
       [-0.73857864, -0.12023846,  1.00603812,  0.85295288],
       [-0.76095981, -0.11222256,  1.09749613,  0.85295288],
       [-0.74976922, -0.12023846,  1.14322514,  1.03572849],
       [-0.67143512, -0.11623051,  1.02890262,  0.91387808],
       [-0.63786337, -0.10420666,  0.8002576 ,  0.60925205],
       [-0.6154822 , -0.09619077,  0.8688511 ,  0.67017726],
       [-0.6154822 , -0.09619077,  0.8459866 ,  0.60925205],
       [-0.64905395, -0.10821461,  0.89171561,  0.73110246],
       [-0.67143512, -0.10821461,  1.16608964,  0.97480329],
       [-0.60429161, -0.12023846,  1.02890262,  0.91387808],
       [-0.67143512, -0.13627025,  1.02890262,  0.97480329],
       [-0.74976922, -0.12424641,  1.07463163,  0.91387808],
       [-0.70500688, -0.09218282,  1.00603812,  0.79202767],
       [-0.62667278, -0.12023846,  0.93744461,  0.79202767],
       [-0.6154822 , -0.10019872,  0.91458011,  0.79202767],
       [-0.6154822 , -0.10420666,  1.00603812,  0.73110246],
       [-0.68262571, -0.12023846,  1.05176713,  0.85295288],
       [-0.64905395, -0.10420666,  0.91458011,  0.73110246],
       [-0.55952927, -0.09218282,  0.75452859,  0.60925205],
       [-0.62667278, -0.10821461,  0.96030911,  0.79202767],
       [-0.63786337, -0.12023846,  0.96030911,  0.73110246],
       [-0.63786337, -0.11623051,  0.96030911,  0.79202767],
       [-0.69381629, -0.11623051,  0.98317362,  0.79202767],
       [-0.57071986, -0.10019872,  0.68593508,  0.67017726],
       [-0.63786337, -0.11222256,  0.93744461,  0.79202767],
       [-0.70500688, -0.13226231,  1.37187016,  1.52313014],
       [-0.64905395, -0.10821461,  1.16608964,  1.1575789 ],
       [-0.79453156, -0.12023846,  1.34900566,  1.27942931],
       [-0.70500688, -0.11623051,  1.28041215,  1.0966537 ],
       [-0.72738805, -0.12023846,  1.32614116,  1.34035452],
       [-0.85048449, -0.12023846,  1.50905718,  1.27942931],
       [-0.54833868, -0.10019872,  1.02890262,  1.03572849],
       [-0.81691273, -0.11623051,  1.44046367,  1.0966537 ],
       [-0.74976922, -0.10019872,  1.32614116,  1.0966537 ],
       [-0.80572215, -0.14428615,  1.39473467,  1.52313014],
       [-0.72738805, -0.12825436,  1.16608964,  1.21850411],
       [-0.71619747, -0.10821461,  1.21181864,  1.1575789 ],
       [-0.76095981, -0.12023846,  1.25754765,  1.27942931],
       [-0.63786337, -0.10019872,  1.14322514,  1.21850411],
       [-0.64905395, -0.11222256,  1.16608964,  1.46220493],
       [-0.71619747, -0.12825436,  1.21181864,  1.40127972],
       [-0.72738805, -0.12023846,  1.25754765,  1.0966537 ],
       [-0.86167508, -0.15230205,  1.53192168,  1.34035452],
       [-0.86167508, -0.10420666,  1.57765069,  1.40127972],
       [-0.67143512, -0.08817487,  1.14322514,  0.91387808],
       [-0.77215039, -0.12825436,  1.30327666,  1.40127972],
       [-0.62667278, -0.11222256,  1.12036063,  1.21850411],
       [-0.86167508, -0.11222256,  1.53192168,  1.21850411],
       [-0.70500688, -0.10821461,  1.12036063,  1.0966537 ],
       [-0.74976922, -0.13226231,  1.30327666,  1.27942931],
       [-0.80572215, -0.12825436,  1.37187016,  1.0966537 ],
       [-0.69381629, -0.11222256,  1.09749613,  1.0966537 ],
       [-0.68262571, -0.12023846,  1.12036063,  1.0966537 ],
       [-0.71619747, -0.11222256,  1.28041215,  1.27942931],
       [-0.80572215, -0.12023846,  1.32614116,  0.97480329],
       [-0.82810332, -0.11222256,  1.39473467,  1.1575789 ],
       [-0.88405625, -0.15230205,  1.46332817,  1.21850411],
       [-0.71619747, -0.11222256,  1.28041215,  1.34035452],
       [-0.70500688, -0.11222256,  1.16608964,  0.91387808],
       [-0.68262571, -0.10420666,  1.28041215,  0.85295288],
       [-0.86167508, -0.12023846,  1.39473467,  1.40127972],
       [-0.70500688, -0.13627025,  1.28041215,  1.46220493],
       [-0.71619747, -0.12424641,  1.25754765,  1.0966537 ],
       [-0.67143512, -0.12023846,  1.09749613,  1.0966537 ],
       [-0.77215039, -0.12424641,  1.23468315,  1.27942931],
       [-0.74976922, -0.12424641,  1.28041215,  1.46220493],
       [-0.77215039, -0.12424641,  1.16608964,  1.40127972],
       [-0.64905395, -0.10821461,  1.16608964,  1.1575789 ],
       [-0.76095981, -0.12825436,  1.34900566,  1.40127972],
       [-0.74976922, -0.13226231,  1.30327666,  1.52313014],
       [-0.74976922, -0.12023846,  1.18895414,  1.40127972],
       [-0.70500688, -0.10019872,  1.14322514,  1.1575789 ],
       [-0.72738805, -0.12023846,  1.18895414,  1.21850411],
       [-0.69381629, -0.13627025,  1.23468315,  1.40127972],
       [-0.66024454, -0.12023846,  1.16608964,  1.0966537 ]])
>>> regressor.coef_ * iris.data + iris.intercept_
>>> regressor.coef_ * iris.data + regressor.intercept_
array([[-0.38422461,  0.04621704,  0.50659829,  0.30834566],
       [-0.36184344,  0.06625679,  0.50659829,  0.30834566],
       [-0.33946227,  0.05824089,  0.48373378,  0.30834566],
       [-0.32827168,  0.06224884,  0.52946279,  0.30834566],
       [-0.37303402,  0.0422091 ,  0.50659829,  0.30834566],
       [-0.41779636,  0.03018525,  0.57519179,  0.43019607],
       [-0.32827168,  0.05022499,  0.50659829,  0.36927086],
       [-0.37303402,  0.05022499,  0.52946279,  0.30834566],
       [-0.30589051,  0.07026474,  0.50659829,  0.30834566],
       [-0.36184344,  0.06224884,  0.52946279,  0.24742045],
       [-0.41779636,  0.03820115,  0.52946279,  0.30834566],
       [-0.35065285,  0.05022499,  0.55232729,  0.30834566],
       [-0.35065285,  0.06625679,  0.50659829,  0.24742045],
       [-0.29469992,  0.06625679,  0.43800478,  0.24742045],
       [-0.46255871,  0.0261773 ,  0.46086928,  0.30834566],
       [-0.45136812,  0.01014551,  0.52946279,  0.43019607],
       [-0.41779636,  0.03018525,  0.48373378,  0.43019607],
       [-0.38422461,  0.04621704,  0.50659829,  0.36927086],
       [-0.45136812,  0.0341932 ,  0.57519179,  0.36927086],
       [-0.38422461,  0.0341932 ,  0.52946279,  0.36927086],
       [-0.41779636,  0.05022499,  0.57519179,  0.30834566],
       [-0.38422461,  0.03820115,  0.52946279,  0.43019607],
       [-0.32827168,  0.0422091 ,  0.41514027,  0.30834566],
       [-0.38422461,  0.05423294,  0.57519179,  0.49112127],
       [-0.35065285,  0.05022499,  0.6209208 ,  0.30834566],
       [-0.37303402,  0.06625679,  0.55232729,  0.30834566],
       [-0.37303402,  0.05022499,  0.55232729,  0.43019607],
       [-0.39541519,  0.04621704,  0.52946279,  0.30834566],
       [-0.39541519,  0.05022499,  0.50659829,  0.30834566],
       [-0.33946227,  0.05824089,  0.55232729,  0.30834566],
       [-0.35065285,  0.06224884,  0.55232729,  0.30834566],
       [-0.41779636,  0.05022499,  0.52946279,  0.43019607],
       [-0.39541519,  0.02216935,  0.52946279,  0.24742045],
       [-0.42898695,  0.0181614 ,  0.50659829,  0.30834566],
       [-0.36184344,  0.06224884,  0.52946279,  0.30834566],
       [-0.37303402,  0.05824089,  0.46086928,  0.30834566],
       [-0.42898695,  0.04621704,  0.48373378,  0.30834566],
       [-0.36184344,  0.0422091 ,  0.50659829,  0.24742045],
       [-0.30589051,  0.06625679,  0.48373378,  0.30834566],
       [-0.38422461,  0.05022499,  0.52946279,  0.30834566],
       [-0.37303402,  0.04621704,  0.48373378,  0.36927086],
       [-0.3170811 ,  0.09431243,  0.48373378,  0.36927086],
       [-0.30589051,  0.05824089,  0.48373378,  0.30834566],
       [-0.37303402,  0.04621704,  0.55232729,  0.55204648],
       [-0.38422461,  0.0341932 ,  0.6209208 ,  0.43019607],
       [-0.35065285,  0.06625679,  0.50659829,  0.36927086],
       [-0.38422461,  0.0341932 ,  0.55232729,  0.30834566],
       [-0.32827168,  0.05824089,  0.50659829,  0.30834566],
       [-0.40660578,  0.03820115,  0.52946279,  0.30834566],
       [-0.37303402,  0.05423294,  0.50659829,  0.30834566],
       [-0.59684573,  0.05824089,  1.26112688,  1.03944812],
       [-0.52970222,  0.05824089,  1.21539787,  1.10037333],
       [-0.58565514,  0.06224884,  1.30685588,  1.10037333],
       [-0.42898695,  0.09431243,  1.10107536,  0.97852292],
       [-0.5408928 ,  0.07427269,  1.23826237,  1.10037333],
       [-0.45136812,  0.07427269,  1.21539787,  0.97852292],
       [-0.51851163,  0.05423294,  1.26112688,  1.16129853],
       [-0.36184344,  0.09030448,  0.94102384,  0.7957473 ],
       [-0.55208339,  0.07026474,  1.23826237,  0.97852292],
       [-0.39541519,  0.07828063,  1.07821085,  1.03944812],
       [-0.37303402,  0.10633627,  0.98675284,  0.7957473 ],
       [-0.47374929,  0.06625679,  1.14680436,  1.10037333],
       [-0.48493988,  0.09832038,  1.10107536,  0.7957473 ],
       [-0.49613046,  0.07026474,  1.26112688,  1.03944812],
       [-0.44017753,  0.07026474,  1.00961735,  0.97852292],
       [-0.56327397,  0.06224884,  1.19253337,  1.03944812],
       [-0.44017753,  0.06625679,  1.21539787,  1.10037333],
       [-0.46255871,  0.07828063,  1.12393986,  0.7957473 ],
       [-0.50732105,  0.09832038,  1.21539787,  1.10037333],
       [-0.44017753,  0.08629653,  1.07821085,  0.85667251],
       [-0.47374929,  0.05824089,  1.28399138,  1.28314894],
       [-0.49613046,  0.07427269,  1.10107536,  0.97852292],
       [-0.51851163,  0.08629653,  1.30685588,  1.10037333],
       [-0.49613046,  0.07427269,  1.26112688,  0.91759771],
       [-0.52970222,  0.07026474,  1.16966886,  0.97852292],
       [-0.55208339,  0.06625679,  1.19253337,  1.03944812],
       [-0.57446456,  0.07427269,  1.28399138,  1.03944812],
       [-0.56327397,  0.06625679,  1.32972038,  1.22222374],
       [-0.48493988,  0.07026474,  1.21539787,  1.10037333],
       [-0.45136812,  0.08228858,  0.98675284,  0.7957473 ],
       [-0.42898695,  0.09030448,  1.05534635,  0.85667251],
       [-0.42898695,  0.09030448,  1.03248185,  0.7957473 ],
       [-0.46255871,  0.07828063,  1.07821085,  0.91759771],
       [-0.48493988,  0.07828063,  1.35258489,  1.16129853],
       [-0.41779636,  0.06625679,  1.21539787,  1.10037333],
       [-0.48493988,  0.05022499,  1.21539787,  1.16129853],
       [-0.56327397,  0.06224884,  1.26112688,  1.10037333],
       [-0.51851163,  0.09431243,  1.19253337,  0.97852292],
       [-0.44017753,  0.06625679,  1.12393986,  0.97852292],
       [-0.42898695,  0.08629653,  1.10107536,  0.97852292],
       [-0.42898695,  0.08228858,  1.19253337,  0.91759771],
       [-0.49613046,  0.06625679,  1.23826237,  1.03944812],
       [-0.46255871,  0.08228858,  1.10107536,  0.91759771],
       [-0.37303402,  0.09431243,  0.94102384,  0.7957473 ],
       [-0.44017753,  0.07828063,  1.14680436,  0.97852292],
       [-0.45136812,  0.06625679,  1.14680436,  0.91759771],
       [-0.45136812,  0.07026474,  1.14680436,  0.97852292],
       [-0.50732105,  0.07026474,  1.16966886,  0.97852292],
       [-0.38422461,  0.08629653,  0.87243033,  0.85667251],
       [-0.45136812,  0.07427269,  1.12393986,  0.97852292],
       [-0.51851163,  0.05423294,  1.55836541,  1.70962538],
       [-0.46255871,  0.07828063,  1.35258489,  1.34407415],
       [-0.60803632,  0.06625679,  1.53550091,  1.46592456],
       [-0.51851163,  0.07026474,  1.4669074 ,  1.28314894],
       [-0.5408928 ,  0.06625679,  1.51263641,  1.52684977],
       [-0.66398924,  0.06625679,  1.69555243,  1.46592456],
       [-0.36184344,  0.08629653,  1.21539787,  1.22222374],
       [-0.63041749,  0.07026474,  1.62695892,  1.28314894],
       [-0.56327397,  0.08629653,  1.51263641,  1.28314894],
       [-0.6192269 ,  0.0422091 ,  1.58122991,  1.70962538],
       [-0.5408928 ,  0.05824089,  1.35258489,  1.40499936],
       [-0.52970222,  0.07828063,  1.39831389,  1.34407415],
       [-0.57446456,  0.06625679,  1.4440429 ,  1.46592456],
       [-0.45136812,  0.08629653,  1.32972038,  1.40499936],
       [-0.46255871,  0.07427269,  1.35258489,  1.64870018],
       [-0.52970222,  0.05824089,  1.39831389,  1.58777497],
       [-0.5408928 ,  0.06625679,  1.4440429 ,  1.28314894],
       [-0.67517983,  0.0341932 ,  1.71841693,  1.52684977],
       [-0.67517983,  0.08228858,  1.76414594,  1.58777497],
       [-0.48493988,  0.09832038,  1.32972038,  1.10037333],
       [-0.58565514,  0.05824089,  1.4897719 ,  1.58777497],
       [-0.44017753,  0.07427269,  1.30685588,  1.40499936],
       [-0.67517983,  0.07427269,  1.71841693,  1.40499936],
       [-0.51851163,  0.07828063,  1.30685588,  1.28314894],
       [-0.56327397,  0.05423294,  1.4897719 ,  1.46592456],
       [-0.6192269 ,  0.05824089,  1.55836541,  1.28314894],
       [-0.50732105,  0.07427269,  1.28399138,  1.28314894],
       [-0.49613046,  0.06625679,  1.30685588,  1.28314894],
       [-0.52970222,  0.07427269,  1.4669074 ,  1.46592456],
       [-0.6192269 ,  0.06625679,  1.51263641,  1.16129853],
       [-0.64160807,  0.07427269,  1.58122991,  1.34407415],
       [-0.697561  ,  0.0341932 ,  1.64982342,  1.40499936],
       [-0.52970222,  0.07427269,  1.4669074 ,  1.52684977],
       [-0.51851163,  0.07427269,  1.35258489,  1.10037333],
       [-0.49613046,  0.08228858,  1.4669074 ,  1.03944812],
       [-0.67517983,  0.06625679,  1.58122991,  1.58777497],
       [-0.51851163,  0.05022499,  1.4669074 ,  1.64870018],
       [-0.52970222,  0.06224884,  1.4440429 ,  1.28314894],
       [-0.48493988,  0.06625679,  1.28399138,  1.28314894],
       [-0.58565514,  0.06224884,  1.42117839,  1.46592456],
       [-0.56327397,  0.06224884,  1.4669074 ,  1.64870018],
       [-0.58565514,  0.06224884,  1.35258489,  1.58777497],
       [-0.46255871,  0.07828063,  1.35258489,  1.34407415],
       [-0.57446456,  0.05824089,  1.53550091,  1.58777497],
       [-0.56327397,  0.05423294,  1.4897719 ,  1.70962538],
       [-0.56327397,  0.06625679,  1.37544939,  1.58777497],
       [-0.51851163,  0.08629653,  1.32972038,  1.34407415],
       [-0.5408928 ,  0.06625679,  1.37544939,  1.40499936],
       [-0.50732105,  0.05022499,  1.42117839,  1.58777497],
       [-0.47374929,  0.06625679,  1.35258489,  1.28314894]])
>>> out = regressor.coef_ * iris.data + regressor.intercept_
>>> out.sum(axis=1)
array([0.47693638, 0.51935729, 0.51085806, 0.5717856 , 0.48411902,
       0.61777675, 0.59782246, 0.51499942, 0.57931817, 0.47728864,
       0.45821323, 0.56024509, 0.46962267, 0.45698209, 0.33283353,
       0.51843624, 0.52631874, 0.53786159, 0.52728774, 0.54870224,
       0.51596608, 0.6136354 , 0.43742335, 0.7363214 , 0.6288386 ,
       0.55389571, 0.65971433, 0.4886103 , 0.46975374, 0.57945157,
       0.57226894, 0.59208749, 0.4036374 , 0.4041184 , 0.53821385,
       0.45442181, 0.40930954, 0.4343844 , 0.55244572, 0.50380883,
       0.52618767, 0.63023598, 0.54442982, 0.77755679, 0.70108546,
       0.59147308, 0.51064154, 0.54491315, 0.46940381, 0.49614286,
       1.76197016, 1.84430987, 1.8838229 , 1.74492375, 1.87201558,
       1.81682535, 1.95814672, 1.46523218, 1.73496664, 1.80052442,
       1.5158024 , 1.83968519, 1.51020316, 1.87470927, 1.61822746,
       1.73095636, 1.94185045, 1.53540909, 1.90677053, 1.58100236,
       2.15163192, 1.6577405 , 1.97501411, 1.75686681, 1.6887543 ,
       1.74615489, 1.82324763, 2.05492694, 1.90109606, 1.41342061,
       1.57333639, 1.48954668, 1.61153049, 2.10722418, 1.96423162,
       1.94198152, 1.86047507, 1.74685708, 1.72854203, 1.73690786,
       1.76343271, 1.84783682, 1.63840295, 1.45804954, 1.76343038,
       1.67929074, 1.7442239 , 1.71113547, 1.43117476, 1.72536734,
       2.8037121 , 2.31238096, 2.45964594, 2.30180945, 2.56485016,
       2.56374453, 2.1620747 , 2.34995511, 2.31880791, 2.71383749,
       2.27493233, 2.29096646, 2.40175969, 2.36964815, 2.61299904,
       2.51462754, 2.25255583, 2.60428007, 2.75902966, 2.04347421,
       2.55013262, 2.34595039, 2.52250914, 2.14977383, 2.44665543,
       2.28052834, 2.13409196, 2.16013115, 2.47740243, 2.12096483,
       2.35796868, 2.39145498, 2.53832763, 2.00871927, 2.09251364,
       2.56008184, 2.64732094, 2.25973846, 2.14845723, 2.36369665,
       2.61458244, 2.41695355, 2.31238096, 2.60705221, 2.69035625,
       2.46620717, 2.24157943, 2.30581273, 2.55185731, 2.22824133])
>>> out.sum(axis=0)
array([-70.11119389,   9.59383457, 156.86148894, 137.57873162])
>>> out.sum(axis=1)
array([0.47693638, 0.51935729, 0.51085806, 0.5717856 , 0.48411902,
       0.61777675, 0.59782246, 0.51499942, 0.57931817, 0.47728864,
       0.45821323, 0.56024509, 0.46962267, 0.45698209, 0.33283353,
       0.51843624, 0.52631874, 0.53786159, 0.52728774, 0.54870224,
       0.51596608, 0.6136354 , 0.43742335, 0.7363214 , 0.6288386 ,
       0.55389571, 0.65971433, 0.4886103 , 0.46975374, 0.57945157,
       0.57226894, 0.59208749, 0.4036374 , 0.4041184 , 0.53821385,
       0.45442181, 0.40930954, 0.4343844 , 0.55244572, 0.50380883,
       0.52618767, 0.63023598, 0.54442982, 0.77755679, 0.70108546,
       0.59147308, 0.51064154, 0.54491315, 0.46940381, 0.49614286,
       1.76197016, 1.84430987, 1.8838229 , 1.74492375, 1.87201558,
       1.81682535, 1.95814672, 1.46523218, 1.73496664, 1.80052442,
       1.5158024 , 1.83968519, 1.51020316, 1.87470927, 1.61822746,
       1.73095636, 1.94185045, 1.53540909, 1.90677053, 1.58100236,
       2.15163192, 1.6577405 , 1.97501411, 1.75686681, 1.6887543 ,
       1.74615489, 1.82324763, 2.05492694, 1.90109606, 1.41342061,
       1.57333639, 1.48954668, 1.61153049, 2.10722418, 1.96423162,
       1.94198152, 1.86047507, 1.74685708, 1.72854203, 1.73690786,
       1.76343271, 1.84783682, 1.63840295, 1.45804954, 1.76343038,
       1.67929074, 1.7442239 , 1.71113547, 1.43117476, 1.72536734,
       2.8037121 , 2.31238096, 2.45964594, 2.30180945, 2.56485016,
       2.56374453, 2.1620747 , 2.34995511, 2.31880791, 2.71383749,
       2.27493233, 2.29096646, 2.40175969, 2.36964815, 2.61299904,
       2.51462754, 2.25255583, 2.60428007, 2.75902966, 2.04347421,
       2.55013262, 2.34595039, 2.52250914, 2.14977383, 2.44665543,
       2.28052834, 2.13409196, 2.16013115, 2.47740243, 2.12096483,
       2.35796868, 2.39145498, 2.53832763, 2.00871927, 2.09251364,
       2.56008184, 2.64732094, 2.25973846, 2.14845723, 2.36369665,
       2.61458244, 2.41695355, 2.31238096, 2.60705221, 2.69035625,
       2.46620717, 2.24157943, 2.30581273, 2.55185731, 2.22824133])
>>> regressor.coef_ * iris.data
array([[-0.57071986, -0.1402782 ,  0.32010304,  0.12185041],
       [-0.54833868, -0.12023846,  0.32010304,  0.12185041],
       [-0.52595751, -0.12825436,  0.29723854,  0.12185041],
       [-0.51476693, -0.12424641,  0.34296754,  0.12185041],
       [-0.55952927, -0.14428615,  0.32010304,  0.12185041],
       [-0.60429161, -0.15631   ,  0.38869655,  0.24370082],
       [-0.51476693, -0.13627025,  0.32010304,  0.18277562],
       [-0.55952927, -0.13627025,  0.34296754,  0.12185041],
       [-0.49238576, -0.11623051,  0.32010304,  0.12185041],
       [-0.54833868, -0.12424641,  0.34296754,  0.06092521],
       [-0.60429161, -0.1482941 ,  0.34296754,  0.12185041],
       [-0.5371481 , -0.13627025,  0.36583204,  0.12185041],
       [-0.5371481 , -0.12023846,  0.32010304,  0.06092521],
       [-0.48119517, -0.12023846,  0.25150953,  0.06092521],
       [-0.64905395, -0.16031795,  0.27437403,  0.12185041],
       [-0.63786337, -0.17634974,  0.34296754,  0.24370082],
       [-0.60429161, -0.15631   ,  0.29723854,  0.24370082],
       [-0.57071986, -0.1402782 ,  0.32010304,  0.18277562],
       [-0.63786337, -0.15230205,  0.38869655,  0.18277562],
       [-0.57071986, -0.15230205,  0.34296754,  0.18277562],
       [-0.60429161, -0.13627025,  0.38869655,  0.12185041],
       [-0.57071986, -0.1482941 ,  0.34296754,  0.24370082],
       [-0.51476693, -0.14428615,  0.22864503,  0.12185041],
       [-0.57071986, -0.13226231,  0.38869655,  0.30462603],
       [-0.5371481 , -0.13627025,  0.43442555,  0.12185041],
       [-0.55952927, -0.12023846,  0.36583204,  0.12185041],
       [-0.55952927, -0.13627025,  0.36583204,  0.24370082],
       [-0.58191044, -0.1402782 ,  0.34296754,  0.12185041],
       [-0.58191044, -0.13627025,  0.32010304,  0.12185041],
       [-0.52595751, -0.12825436,  0.36583204,  0.12185041],
       [-0.5371481 , -0.12424641,  0.36583204,  0.12185041],
       [-0.60429161, -0.13627025,  0.34296754,  0.24370082],
       [-0.58191044, -0.16432589,  0.34296754,  0.06092521],
       [-0.6154822 , -0.16833384,  0.32010304,  0.12185041],
       [-0.54833868, -0.12424641,  0.34296754,  0.12185041],
       [-0.55952927, -0.12825436,  0.27437403,  0.12185041],
       [-0.6154822 , -0.1402782 ,  0.29723854,  0.12185041],
       [-0.54833868, -0.14428615,  0.32010304,  0.06092521],
       [-0.49238576, -0.12023846,  0.29723854,  0.12185041],
       [-0.57071986, -0.13627025,  0.34296754,  0.12185041],
       [-0.55952927, -0.1402782 ,  0.29723854,  0.18277562],
       [-0.50357634, -0.09218282,  0.29723854,  0.18277562],
       [-0.49238576, -0.12825436,  0.29723854,  0.12185041],
       [-0.55952927, -0.1402782 ,  0.36583204,  0.36555123],
       [-0.57071986, -0.15230205,  0.43442555,  0.24370082],
       [-0.5371481 , -0.12023846,  0.32010304,  0.18277562],
       [-0.57071986, -0.15230205,  0.36583204,  0.12185041],
       [-0.51476693, -0.12825436,  0.32010304,  0.12185041],
       [-0.59310103, -0.1482941 ,  0.34296754,  0.12185041],
       [-0.55952927, -0.13226231,  0.32010304,  0.12185041],
       [-0.78334098, -0.12825436,  1.07463163,  0.85295288],
       [-0.71619747, -0.12825436,  1.02890262,  0.91387808],
       [-0.77215039, -0.12424641,  1.12036063,  0.91387808],
       [-0.6154822 , -0.09218282,  0.91458011,  0.79202767],
       [-0.72738805, -0.11222256,  1.05176713,  0.91387808],
       [-0.63786337, -0.11222256,  1.02890262,  0.79202767],
       [-0.70500688, -0.13226231,  1.07463163,  0.97480329],
       [-0.54833868, -0.09619077,  0.75452859,  0.60925205],
       [-0.73857864, -0.11623051,  1.05176713,  0.79202767],
       [-0.58191044, -0.10821461,  0.89171561,  0.85295288],
       [-0.55952927, -0.08015897,  0.8002576 ,  0.60925205],
       [-0.66024454, -0.12023846,  0.96030911,  0.91387808],
       [-0.67143512, -0.08817487,  0.91458011,  0.60925205],
       [-0.68262571, -0.11623051,  1.07463163,  0.85295288],
       [-0.62667278, -0.11623051,  0.8231221 ,  0.79202767],
       [-0.74976922, -0.12424641,  1.00603812,  0.85295288],
       [-0.62667278, -0.12023846,  1.02890262,  0.91387808],
       [-0.64905395, -0.10821461,  0.93744461,  0.60925205],
       [-0.69381629, -0.08817487,  1.02890262,  0.91387808],
       [-0.62667278, -0.10019872,  0.89171561,  0.67017726],
       [-0.66024454, -0.12825436,  1.09749613,  1.0966537 ],
       [-0.68262571, -0.11222256,  0.91458011,  0.79202767],
       [-0.70500688, -0.10019872,  1.12036063,  0.91387808],
       [-0.68262571, -0.11222256,  1.07463163,  0.73110246],
       [-0.71619747, -0.11623051,  0.98317362,  0.79202767],
       [-0.73857864, -0.12023846,  1.00603812,  0.85295288],
       [-0.76095981, -0.11222256,  1.09749613,  0.85295288],
       [-0.74976922, -0.12023846,  1.14322514,  1.03572849],
       [-0.67143512, -0.11623051,  1.02890262,  0.91387808],
       [-0.63786337, -0.10420666,  0.8002576 ,  0.60925205],
       [-0.6154822 , -0.09619077,  0.8688511 ,  0.67017726],
       [-0.6154822 , -0.09619077,  0.8459866 ,  0.60925205],
       [-0.64905395, -0.10821461,  0.89171561,  0.73110246],
       [-0.67143512, -0.10821461,  1.16608964,  0.97480329],
       [-0.60429161, -0.12023846,  1.02890262,  0.91387808],
       [-0.67143512, -0.13627025,  1.02890262,  0.97480329],
       [-0.74976922, -0.12424641,  1.07463163,  0.91387808],
       [-0.70500688, -0.09218282,  1.00603812,  0.79202767],
       [-0.62667278, -0.12023846,  0.93744461,  0.79202767],
       [-0.6154822 , -0.10019872,  0.91458011,  0.79202767],
       [-0.6154822 , -0.10420666,  1.00603812,  0.73110246],
       [-0.68262571, -0.12023846,  1.05176713,  0.85295288],
       [-0.64905395, -0.10420666,  0.91458011,  0.73110246],
       [-0.55952927, -0.09218282,  0.75452859,  0.60925205],
       [-0.62667278, -0.10821461,  0.96030911,  0.79202767],
       [-0.63786337, -0.12023846,  0.96030911,  0.73110246],
       [-0.63786337, -0.11623051,  0.96030911,  0.79202767],
       [-0.69381629, -0.11623051,  0.98317362,  0.79202767],
       [-0.57071986, -0.10019872,  0.68593508,  0.67017726],
       [-0.63786337, -0.11222256,  0.93744461,  0.79202767],
       [-0.70500688, -0.13226231,  1.37187016,  1.52313014],
       [-0.64905395, -0.10821461,  1.16608964,  1.1575789 ],
       [-0.79453156, -0.12023846,  1.34900566,  1.27942931],
       [-0.70500688, -0.11623051,  1.28041215,  1.0966537 ],
       [-0.72738805, -0.12023846,  1.32614116,  1.34035452],
       [-0.85048449, -0.12023846,  1.50905718,  1.27942931],
       [-0.54833868, -0.10019872,  1.02890262,  1.03572849],
       [-0.81691273, -0.11623051,  1.44046367,  1.0966537 ],
       [-0.74976922, -0.10019872,  1.32614116,  1.0966537 ],
       [-0.80572215, -0.14428615,  1.39473467,  1.52313014],
       [-0.72738805, -0.12825436,  1.16608964,  1.21850411],
       [-0.71619747, -0.10821461,  1.21181864,  1.1575789 ],
       [-0.76095981, -0.12023846,  1.25754765,  1.27942931],
       [-0.63786337, -0.10019872,  1.14322514,  1.21850411],
       [-0.64905395, -0.11222256,  1.16608964,  1.46220493],
       [-0.71619747, -0.12825436,  1.21181864,  1.40127972],
       [-0.72738805, -0.12023846,  1.25754765,  1.0966537 ],
       [-0.86167508, -0.15230205,  1.53192168,  1.34035452],
       [-0.86167508, -0.10420666,  1.57765069,  1.40127972],
       [-0.67143512, -0.08817487,  1.14322514,  0.91387808],
       [-0.77215039, -0.12825436,  1.30327666,  1.40127972],
       [-0.62667278, -0.11222256,  1.12036063,  1.21850411],
       [-0.86167508, -0.11222256,  1.53192168,  1.21850411],
       [-0.70500688, -0.10821461,  1.12036063,  1.0966537 ],
       [-0.74976922, -0.13226231,  1.30327666,  1.27942931],
       [-0.80572215, -0.12825436,  1.37187016,  1.0966537 ],
       [-0.69381629, -0.11222256,  1.09749613,  1.0966537 ],
       [-0.68262571, -0.12023846,  1.12036063,  1.0966537 ],
       [-0.71619747, -0.11222256,  1.28041215,  1.27942931],
       [-0.80572215, -0.12023846,  1.32614116,  0.97480329],
       [-0.82810332, -0.11222256,  1.39473467,  1.1575789 ],
       [-0.88405625, -0.15230205,  1.46332817,  1.21850411],
       [-0.71619747, -0.11222256,  1.28041215,  1.34035452],
       [-0.70500688, -0.11222256,  1.16608964,  0.91387808],
       [-0.68262571, -0.10420666,  1.28041215,  0.85295288],
       [-0.86167508, -0.12023846,  1.39473467,  1.40127972],
       [-0.70500688, -0.13627025,  1.28041215,  1.46220493],
       [-0.71619747, -0.12424641,  1.25754765,  1.0966537 ],
       [-0.67143512, -0.12023846,  1.09749613,  1.0966537 ],
       [-0.77215039, -0.12424641,  1.23468315,  1.27942931],
       [-0.74976922, -0.12424641,  1.28041215,  1.46220493],
       [-0.77215039, -0.12424641,  1.16608964,  1.40127972],
       [-0.64905395, -0.10821461,  1.16608964,  1.1575789 ],
       [-0.76095981, -0.12825436,  1.34900566,  1.40127972],
       [-0.74976922, -0.13226231,  1.30327666,  1.52313014],
       [-0.74976922, -0.12023846,  1.18895414,  1.40127972],
       [-0.70500688, -0.10019872,  1.14322514,  1.1575789 ],
       [-0.72738805, -0.12023846,  1.18895414,  1.21850411],
       [-0.69381629, -0.13627025,  1.23468315,  1.40127972],
       [-0.66024454, -0.12023846,  1.16608964,  1.0966537 ]])
>>> # y_hat = B_0 + B_1 * x_1 + B_2 * x_2 + B_3 * x_3 + B_4 * x_4
>>> y_hat
-0.08254936159009345
>>> preds[0]
-0.08254936159009335
>>> clera
>>> clear
>>> # Slide 104
>>> from sklearn import datasets
>>> from sklearn.model_selection import train_test_split
>>> from collections import Counter
>>>  iris = datasets.load_iris()
>>> iris.data.shape
(150, 4)
>>> iris.targer.shape
>>> iris.targer.shapt
>>> iris.target.shape
(150,)
>>> iris.data.shape
(150, 4)
>>> iris.targer
>>> iris.target
array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
>>> Counter(iris.target)
Counter({0: 50, 1: 50, 2: 50})
>>> import pandas as pd
>>> s = pd.Series(iris.data)
>>> s = pd.Series(iris.target)
>>> s
0      0
1      0
2      0
3      0
4      0
      ..
145    2
146    2
147    2
148    2
149    2
Length: 150, dtype: int64
>>> s.value_counts()
2    50
1    50
0    50
dtype: int64
>>> Counter(iris.target)
Counter({0: 50, 1: 50, 2: 50})
>>> # I could split manually
>>> train_split = 0.70
>>> train_split * len(iris.data)
105.0
>>> train = iris.target[:105]
>>> test = iris.target[105:]
>>> train.shape
(105,)
>>> test.shape
(45,)
>>> train
array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2])
>>> test
array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2])
>>> iris.targer
>>> iris.target
array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
>>> train
array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2])
>>> test
array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2])
>>> X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, train_size=0.7)
>>> X_train.shape
(105, 4)
>>> X_test.shape
(45, 4)
>>> y_train.shape
(105,)
>>> y_test.shape
(45,)
>>> y_train
array([0, 1, 1, 0, 2, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 2, 1, 0, 1, 2, 2, 1,
       0, 0, 2, 0, 1, 0, 0, 2, 1, 0, 1, 1, 0, 0, 0, 2, 0, 0, 1, 2, 0, 2,
       2, 2, 0, 2, 1, 2, 1, 0, 2, 0, 2, 0, 2, 1, 1, 1, 0, 0, 1, 0, 2, 2,
       2, 1, 2, 2, 1, 1, 1, 2, 2, 2, 2, 0, 1, 2, 1, 1, 2, 2, 2, 1, 2, 0,
       2, 2, 2, 0, 1, 0, 0, 2, 0, 0, 0, 2, 1, 1, 2, 1, 0])
>>> y_test
array([0, 1, 1, 2, 1, 1, 2, 2, 1, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 1, 1, 0,
       1, 2, 1, 0, 1, 1, 2, 0, 2, 0, 1, 2, 0, 0, 2, 2, 1, 1, 0, 2, 2, 2,
       0])
>>> # Observation 1: train_test_split shuffles for us and retains the connection between the feature matrix and the targets
>>> Counter(iris.target)
Counter({0: 50, 1: 50, 2: 50})
>>> Counter(y_train)
Counter({0: 33, 1: 36, 2: 36})
>>> Counter(y_test)
Counter({0: 17, 1: 14, 2: 14})
>>> X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, train_size=0.7)
>>> y_train
array([0, 2, 2, 1, 1, 0, 0, 2, 0, 2, 0, 2, 0, 0, 2, 1, 1, 2, 1, 0, 0, 1,
       2, 0, 0, 2, 2, 0, 1, 0, 2, 0, 0, 1, 2, 1, 0, 1, 1, 1, 1, 1, 2, 0,
       2, 1, 0, 0, 1, 2, 2, 1, 0, 2, 0, 0, 1, 1, 2, 2, 0, 0, 1, 0, 2, 1,
       0, 2, 2, 2, 2, 0, 0, 1, 2, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 2, 1, 0,
       2, 1, 1, 2, 2, 1, 1, 0, 1, 0, 0, 2, 2, 2, 2, 0, 1])
>>> X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, train_size=0.7, random_state=42)
>>> y_train
array([1, 2, 2, 1, 2, 1, 2, 1, 0, 2, 1, 0, 0, 0, 1, 2, 0, 0, 0, 1, 0, 1,
       2, 0, 1, 2, 0, 2, 2, 1, 1, 2, 1, 0, 1, 2, 0, 0, 1, 1, 0, 2, 0, 0,
       1, 1, 2, 1, 2, 2, 1, 0, 0, 2, 2, 0, 0, 0, 1, 2, 0, 2, 2, 0, 1, 1,
       2, 1, 2, 0, 2, 1, 2, 1, 1, 1, 0, 1, 1, 0, 1, 2, 2, 0, 1, 2, 2, 0,
       2, 0, 1, 2, 2, 1, 2, 1, 1, 2, 2, 0, 1, 2, 0, 1, 2])
>>> X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, train_size=0.7, random_state=42)
>>> y_train
array([1, 2, 2, 1, 2, 1, 2, 1, 0, 2, 1, 0, 0, 0, 1, 2, 0, 0, 0, 1, 0, 1,
       2, 0, 1, 2, 0, 2, 2, 1, 1, 2, 1, 0, 1, 2, 0, 0, 1, 1, 0, 2, 0, 0,
       1, 1, 2, 1, 2, 2, 1, 0, 0, 2, 2, 0, 0, 0, 1, 2, 0, 2, 2, 0, 1, 1,
       2, 1, 2, 0, 2, 1, 2, 1, 1, 1, 0, 1, 1, 0, 1, 2, 2, 0, 1, 2, 2, 0,
       2, 0, 1, 2, 2, 1, 2, 1, 1, 2, 2, 0, 1, 2, 0, 1, 2])
>>> Counter(iris.target)
Counter({0: 50, 1: 50, 2: 50})
>>> Counter(y_train)
Counter({1: 37, 2: 37, 0: 31})
>>> Counter(y_test)
Counter({1: 13, 0: 19, 2: 13})
>>> # Stratifcation is always a good idea
>>> X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, train_size=0.7, random_state=42, stratify=iris.target)
>>> Counter(iris.target)
Counter({0: 50, 1: 50, 2: 50})
>>> Counter(y_train)
Counter({1: 35, 0: 35, 2: 35})
>>> Counter(y_test)
Counter({2: 15, 1: 15, 0: 15})
>>> # We cannot use stratification on a continuous variable (regression)
>>> # discretization / binning (pd.cut and pd.qcut)
>>> # Slide 106
>>> clear
>>> from sklearn import datasets
>>> from sklearn.model_selection import train_test_split
>>> from collections import Counter
>>> digits = datasets.load_digits()
>>> digits.target
array([0, 1, 2, ..., 8, 9, 8])
>>> Count(digits.target)
>>> Counter(digits.target)
Counter({0: 178,
         1: 182,
         2: 177,
         3: 183,
         4: 181,
         5: 182,
         6: 181,
         7: 179,
         8: 174,
         9: 180})
>>> X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target, test_size=0.2)
>>> X_train.shape
(1437, 64)
>>> X_test.shape
(360, 64)
>>> len(digits.data)
1797
>>> .8*1797
1437.6000000000001
>>> .2*1797
359.40000000000003
>>> Counter(digits.target)
Counter({0: 178,
         1: 182,
         2: 177,
         3: 183,
         4: 181,
         5: 182,
         6: 181,
         7: 179,
         8: 174,
         9: 180})
>>> Counter(y_train)
Counter({2: 147,
         9: 132,
         5: 154,
         4: 146,
         6: 149,
         7: 145,
         1: 142,
         8: 135,
         0: 137,
         3: 150})
>>> Counter(y_test)
Counter({7: 34, 0: 41, 3: 33, 5: 28, 8: 39, 9: 48, 1: 40, 6: 32, 2: 30, 4: 35})
>>> # Better  soltion
>>> import pandas as pd
>>> raw_counts = pd.Series(digits.target).value_counts()
>>> raw_counts
3    183
5    182
1    182
6    181
4    181
9    180
7    179
0    178
2    177
8    174
dtype: int64
>>> train_counts = pd.Series(y_train).value_counts()
>>> train_counts
5    154
3    150
6    149
2    147
4    146
7    145
1    142
0    137
8    135
9    132
dtype: int64
>>> test_counts = pd.Series(y_test).value_counts()
>>> test_counts
9    48
0    41
1    40
8    39
4    35
7    34
3    33
6    32
2    30
5    28
dtype: int64
>>> (raw_counts/raw_counts.sum())
3    0.101836
5    0.101280
1    0.101280
6    0.100723
4    0.100723
9    0.100167
7    0.099610
0    0.099054
2    0.098497
8    0.096828
dtype: float64
>>> (raw_counts/raw_counts.sum()).sort_index()
0    0.099054
1    0.101280
2    0.098497
3    0.101836
4    0.100723
5    0.101280
6    0.100723
7    0.099610
8    0.096828
9    0.100167
dtype: float64
>>> (train_counts/train_counts.sum()).sort_index()
0    0.095338
1    0.098817
2    0.102296
3    0.104384
4    0.101601
5    0.107168
6    0.103688
7    0.100905
8    0.093946
9    0.091858
dtype: float64
>>> (test_counts/test_counts.sum()).sort_index()
0    0.113889
1    0.111111
2    0.083333
3    0.091667
4    0.097222
5    0.077778
6    0.088889
7    0.094444
8    0.108333
9    0.133333
dtype: float64
>>> X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target, test_size=0.2, stratify=digits.target)
>>> train_counts = pd.Series(y_train).value_counts()
>>> test_counts = pd.Series(y_test).value_counts()
>>> (raw_counts/raw_counts.sum()).sort_index()
0    0.099054
1    0.101280
2    0.098497
3    0.101836
4    0.100723
5    0.101280
6    0.100723
7    0.099610
8    0.096828
9    0.100167
dtype: float64
>>> (train_counts/train_counts.sum()).sort_index()
0    0.098817
1    0.100905
2    0.098817
3    0.101601
4    0.100905
5    0.101601
6    0.100905
7    0.099513
8    0.096729
9    0.100209
dtype: float64
>>> (test_counts/test_counts.sum()).sort_index()
0    0.100000
1    0.102778
2    0.097222
3    0.102778
4    0.100000
5    0.100000
6    0.100000
7    0.100000
8    0.097222
9    0.100000
dtype: float64
>>> ls
>>> %history -pof day2_AM.txt
